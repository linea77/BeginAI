<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <title>Basic</title>
    <link rel="stylesheet" href="./docs/CSS/beginAI.css">
    <script src="http://code.jquery.com/jquery-latest.js"></script>
  </head>

  <body>
    <header>
      <div id="logo">
        <span style="font-size:45px;">Begin AI</span><br>
        <span style="font-size:20px;">미래의 언어학자 프로젝트</span>
      </div>
      <nav>
        <ul>
          <li><a href="index.html" >Home</a></li>
          <li><a  href="01.html">Intro</a></li>
          <li><a class="current-menu" href="02.html">Basic</a></li>
          <li><a href="03.html">Futher</a></li>
        </ul>
      </nav>
    </header>



    <div id="container">
      <ul class="tabs">
        <li class="tab-link current" data-tab="tab-1">04 딥러닝 원리 이해</li>
        <li class="tab-link" data-tab="tab-2">05 인공신경망 신호 전달 원리</li>
        <li class="tab-link" data-tab="tab-3">06 인공신경망 학습 원리</li>
      </ul>

      <section id="tab-1" class="tab-content current">
        <h1>04. 딥러닝 원리 이해하기</h1>
        <hr>
        <div class="subsections">
          <h2> 04-1. 인공지능의 추론 과정 </h2>
          <ol>
          <img src=".\docs\pictures\02\02-1.jpeg" alt="" width=500 border="1" hspace="10">
           <li>인공지능이 지금까지 학습한 데이터와 동일한 형태의 데이터를 인공지능에 넣음</li>
            <li>넣은 데이터가 검은색 박스를 지나, 결과를 보여줌</li>
          </ol>
          <p>
            이 때, 검은색 박스를 어떻게 만들지를 결정하는 것이 머신러닝의 다양한 방법들이며,
            그 중에서 인공신경망에 초점을 맞춰 살펴 볼 예정임.
          </p>
        </div>

        <div class = "subsections">
          <h2> 04-2. 인공신경망 방식으로 만든 인공지능</h2>
            <h3> ◦ 인공신경망(ANN, Artificial Neural Network)</h3>
            <ul>
              <li>사람들이 인공적으로 만든 신경망(neural Network)를 의미함.</li>
              <li>신경망의 최소 구성 단위인 뉴런이 다른 뉴런과 연결된 모습을 각각의 층,<br>
              즉 레이어(layer)라는 개념을 사용하여 연결함</li>
              <img src=".\docs\pictures\02\02-2.png" alt="" width=500 border="1" hspace="10">
            </ul>

            <ul>
              <li>입력층 : 데이터를 입력받는 층</li>
              <li>은닉층 : 입력층에서 들어온 데이터가 여러 신호로 바뀌어서 출력층까지 전달됨.
              - 은닉층이 여러 층일 수록 더 정확하게 출력층으로 신호를 전달할 수 있음.</li>
              <li>출력층 : 결괏값이 나오는 층. 이 출력층에 어떠한 값이 전달되었냐에 따라 인공지능의 에측 값이 결정됨.</li>
            </ul>
            <h3> ◦ 딥러닝(Deep learning)</h3>
            <ul>
              <li>딥러닝은 사람의 뇌에서 이루어지는 원리를 이용하여 인공지능을 만드는 방식.</li>
              <li>레이어가 여러 개의 층으로 구성된 인공신경망을 심층 신경망(DNN, Deep Neural Network)이라고 부르며,<br>
              이 심층 신경망이 학습하는 과정을 딥러닝(Deep Learning)이라고 함.</li>
            </ul>
            <h3> ◦ 여러 특징(feature)을 가진 데이터</h3>
            <ul>
              <li>각각의 데이터에 하나의 정보가 아닌 여러 정보가 있어야 함.<br>
              예) 키, 몸무게, 머리카락 길이, 얼굴 길이, 눈, 코, 입의 형태, 몸의 모습 등</li>
              <li>정보가 많을 수록 성별을 더 정확하게 판단할 수 있다.</li>
            </ul>
            <h3> ◦ 인공 신경망의 추론 과정</h3>
            <ul>
              <li>입력한 데이터가 여러 레이어를 지나가면서 특정한 신호로 전달됨.</li>
              <li>어느 쪽으로 신호가 많이 가는지를 살펴본 후, 신호가 많이 간 쪽으로 결과를 내는 것.</li><br>
              <img src=".\docs\pictures\02\02-3.jpeg" alt="" width=500 border="1" hspace="10"><br>
              <li>이 때 모델이 신호를 정확한 출력값으로 보내지 않는다면,<br>
                정확한 출력값으로 보낼 수 있도록 신호 세기를 조정하는 과정이 바로 인공 신경망의 학습과정임.</li><br>
            </ul>
        </div>
      </section>

      <section  id="tab-2" class="tab-content">
        <h1>05. 인공 신경망의 신호 전달 원리</h1>
        <div class="subsections">
          <h2>05-1. 신호를 전달할 때 사용하는 가중치와 편향</h2>
          <ul>
            <li>여러 뉴런에서 신호를 전달받는 뉴런처럼, 인공 신경망은 단순히 신호를 전달해주는 것이 아니라 신호 세기를 변경해서 전달함<br</li>
            <li>뒤쪽으로 전달되는 신호 세기는 앞쪽 뉴런에서 전달된 신호의 값에 <b>가중치(weight)</b>를 곱하고, <b>편향(bias)</b>을 더해서 다음으로 전달함<br></li>
            <img src=".\docs\pictures\02\02-4.png" alt="" width=500 border="1" hspace="10"><br>
            <li>가중치(weight): 그 값이 얼마나 중요한지를 표현하기 위한 도구, 인공신경망에서는 각 뉴런에서 다음 뉴런으로 신호를 전달할 때 그 값의 중요도를 표현<br></li>
            <li>편향(bias): 한쪽으로 치우침, 인공신경망에서는 모델의 성능을 높이기 위해 가중치를 거쳐 변환된 신호 세기를 조절할 필요가 있는데, 이를 위해 한쪽으로 치우치는 값을 더할 때 사용<br></li>
            <img src=".\docs\pictures\02\02-5.png" alt="" width=500 border="1" hspace="10"><br>
            <li> 가중치는 심층 신경망의 각 뉴런과 뉴런을 연결하는 선에 각각 서로 다른 값의 형태로 저장되어 있음, 인공신경망의 층이 깊어질수록 이 가중치 값은 그에 비례하여 증가함<br></li>
            <li>편향은 각 층에서 하나의 값으로 존재함<br></li>
            <li>"인공신경망이 학습한다" = "가중치와 편향값을 각 데이터에 맞게끔 정교하게 맞추어 간다"<br></li>
          </ul>
        </div>
        <div class="subsections">
          <h2>05-2.들어오는 신호 세기를 조절하는 활성화 함수</h2>
          <ul>
            <li>심층 신경망의 뉴런은 단일 방향으로 연결되어 있는 여러 뉴런들에게 신호를 전달함 → 인공 신경망은 이러한 뇌 속 신경망을 흉내낸 것</li>
            <li>사람의 신경망은 앞쪽 뉴런에게서 받은 신호를 뒤쪽 뉴런에게 전달할지 말지를 결정할 수 있음 → 이때 사용되는 개념이 <b>역치(action potential)</b> 이고,
            이를 인공 신경망에 구현하기 위해 <b>활성화(activation) 함수</b>를 사용</li>
            <img src=".\docs\pictures\02\02-6.png" alt="" width=500 border="1" hspace="10"><br>
            <li>활성화 함수: 여러 뉴런에서 들어온 신호 세기를 특정한 값을 바꾸기 위해 사용, 신호 세기를 조절하는데, 특 레이어와 레이어 사이에 있어서 여러 뉴런에서 특정한 뉴런으로 들어가는 신호를 종합하여 하나의 값으로 바꿔줌</li>
            <img src=".\docs\pictures\02\02-7.png" alt="" width=500 border="1" hspace="10"><br>

            <div>
              <h3> ◦ 활성화 함수의 종류</h3>
              <ul>
                <li class="hidden-list">
                  1-1. 시그모이드(Sigmoid) 함수<br>
                  <img src=".\docs\pictures\02\02-8.png" alt="" width=500 border="1" hspace="10"><br>
                  <ul>
                    <li>로지스틱 함수</li>
                    <li>다양한 곳에서 사용(주로 생태학)</li>
                    <li>처음에는 서서히 증가하다가 어느 순간 그 증가하는 양이 많아짐, 그리고 마지막에는 증가하는 양이 서서히 줄어듦 → 어떤 생물이 어떤 식으로 증가하는 설명하는 모델</li>
                  </ul>
                </li>
                <li class="hidden-list">1-2. 시그모이드 곡선: 로지스틱 곡선의 특수한 사례<br>
                  <img src=".\docs\pictures\02\02-9.png" alt="" width=500 border="1" hspace="10"><br>
                  <ul>
                    <li>로지스틱 함수와 비슷한 S자 모양</li>
                    <li>양수를 입력값으로 넣으면 출력값이 1에 가까워짐 / 음수를 입력값으로 넣으면 출력값이 0에 가까워짐</li>
                    <li>여러 뉴런에서 들어온 신호 세기가 0보다 클수록 1에 가까운 숫자, 0보다 작을 수록 0에 가까운 숫자로 바꾸어 줌</li>
                  </ul>
                </li>
                <li class="hidden-list">
                  2. 하이퍼볼릭탄젠트(Tanh) 함수<br>
                  <img src=".\docs\pictures\02\02-10.png" alt="" width=500 border="1" hspace="10"><br>
                  <ul>
                  <li>시그모이드 함수와 형태가 비슷하나, 입력값이 음수일 때 출력값이 -1에 가까워진다는 차이점이 있음</li>
                  <li>출력값이 0에 가까워지면 신경망이 잘 학습하지 못하는 시그모이드 함수의 한계 보완<br>
                      +) 하이퍼볼릭: 쌍곡선(두 지점에서의 거리가 같은 곡선)</li>
                  </ul>
                </li>

                <li class="hidden-list">
                  3. 렐루(ReLU) 함수<br>
                  <img src=".\docs\pictures\02\02-11.png" alt="" width=500 border="1" hspace="10"><br>
                  <ul>
                    <li>(가장 좌측) 입력값이 음수일 경우 0 출력 / 입력값이 양수일 경우 입력값 그대로 출력</li>
                    <li>ReLU(Rectified Linear Unit) = Rectified(고르게 한) + Linear Unit(직선으로 이루어진)</li>
                    <li>입력값이 아무리 커도 1보다 큰 출력이 나오지 않는 시그모이드, 하이퍼볼릭탄젠트 함수의 단점을 해결</li>
                    <li>그러나 렐루 함수 또한 입력값이 음수일 경우 출력값이 0으로 같다는 단점이 있어 아래와 같은 Leaky 렐루(Leaky ReLU) 함수로 보완함<br>
                  </ul>
                  <li><img src=".\docs\pictures\02\02-12.png" alt="" width=500 border="1" hspace="10"></li>
                  <ul>
                    <li>렐루 함수와 달리, 음수일 경우 양수일 경우의 기울기와 다른 완만한 기울기에 따라 미세하게나마 차이나는 음수 값을 전달함</li>
                  </ul>
                </li>
                
              </ul>
            </div>
            <div>
              <h3> ◦ 소프트맥스 함수</h3>
              <ul>
                <li>출력층에서 주로 사용되는 함수</li>
                <li> 정확한 기준으로 두 값을 비교하기 위해 최종 결괏값을 <b>정규화(normalization)</b> 과정에 사용</li>
                <li> 정규화: 특정한 범위를 지정해주고 데이터를 그 범위 중 하나로 바꾸어주는 것, 가장 작은 데이터를 0으로 가장 큰 데이터를 1로 바꾸고, 그 사이의 값을 크기에 따라 0과 1 사이의 값으로 변환</li>
                <li> 모든 출력층의 값을 더해 1이 되도록 값을 바꿈</li>
                <li> 인공 신경망 모델에서 항상 사용X, 분류 문제에서 사용되는 함수</li>
                <img src=".\docs\pictures\02\02-13.png" alt="" width=500 border="1" hspace="10"><br>
              </ul>
            </div>
          </ul>
        </div>
      </section>

      <section  id="tab-3" class="tab-content">
        <h1>06. 인공 신경망의 학습 원리</h1>
        <div class="subsections">
          <h2>06-1. 인공지능의 학습이란? </h2>
          <p>: 특정 데이터를 넣고 출력값과 정답을 비교해보며 인공 신경망의 예측 성능을 계속해서 높여 나가는 과정</p>
          <h3> ◦ 인공 신경망의 오차 구하기</h3>
          <ul>
              <h4>1) 남녀를 구분하는 인공지능 모델의 오차 구하기</h4>
              <ul>
                <li>이진 분류 문제 : 둘 중 하나로 구분하는 인공지능</li>
                <li>이항 교차 엔트로피 (바이너리 크로스엔트로피, binary crossentropy)<br>
                  : 잘 예측했다면 오차값 0 부여 / 잘못 예측했다면 오차값을 크게 부여<br>
                  → 인공지능이 잘 맞춘다면 오차값은 0에 가깝고, 그렇지 않으면 오차값이 커짐<br>
                  <p class="need-indent">
                    ex) <br>
                      남성을 남성으로 판단할 경우 → 오차값 0<br>
                      남성을 여성으로 판단할 경우 → 오차값 크게 부여<br>
                      여성을 여성으로 판단할 경우 → 오차값 0<br>
                      여성을 남성으로 판단할 경우 → 오차값 크게 부여<br>
                  </p>
                </li>
              </ul>

              <h4>2) 나이대를 예측하는 인공지능 모델의 오차 구하기</h4>
              <ul>
                  <li> 다중 분류 문제 : 여럿 중 하나로 구분하는 인공지능<br></li>
                  <li>다중 분류 손실 함수 (카테고리컬 크로스엔트로피, categorical crossentropy) :<br>
                      정답을 예측할 경우 오차값 0 부여<br>
                      정답이 아닌 값을 높은 확률로 예측하면 오차값을 크게 부여<br>
                      정답이 아닌 값을 낮은 확률로 예측하면 오차값을 적게 부여<br>
                    <p class="need-indent">
                      ex) 정답이 20대 이하일 때: <br>
                        20대 이하일 확률이 30%라고 예측한 결과 → 오차값 0<br>
                        30~40대로 예측한 결과 60% → 큰 오차값 부여<br>
                        50대 이상으로 예측한 결과 10% → 작은 오차값 부여<br>
                    </p>
                  </li>
                </ul>


              <h4>3) 나이를 예측하는 인공지능 모델의 오차 구하기</h4>
              <ul>
                <li>- 회귀 문제 : 특정한 값을 예측하는 인공지능<br></li>
                <li>정답값과 예측 값의 차이를 구한 후 이 값들을 모두 더해 오차값을 계산하는 방법<br>
                → 평균 제곱 오차 (mean squared error) : 정답값과 예측값의 차를 제곱한 값을 통해 실제 값과 오차값의 거리를 측정하는 방법<br></li>
              </ul>
          </ul>
          <h3> ◦ 인공 신경망의 오차 줄이기</h3>
          <ul>
            <h4>1) 경사 하강법</h4>
            <ul>
                <li>기울기로 가중치 값을 변경하는 방법 (미분 사용)</li>
                <img src=".\docs\pictures\02\02-14.png" alt="" width=500 border="1" hspace="10"><br>
                <li>오차 그래프에서 가장 오차가 작은 지점을 파악해 가중치를 수정</li>
                <li>오차가 작은 지점으로 이동하기 위해 기울기가 점점 줄어드는 방향으로 가중치 값을 이동</li>
                <li> 기울기를 통해 다음 값 예측 가능
                  <p>
                  ex) 기울기 大 → 다음 값 변화 大<br>
                      기울기 小 → 다음 값 변화 小
                  </p>
                </li>
                <li>- 옵티마이저 (optimizer) : 경사 하강법을 이용할 때 가중치를 얼마 정도 이동할 것인지 결정</li>
              </ul>
            <h4>2) 오차 역전파법</h4>
            <ul>
                <li>여러 가중치를 차례로 변경해 나가는 방법</li>
                <li>인공 신경망의 층이 여러개일 때 뒤에서부터 앞으로 가중치의 값을 수정해 나감<br></li>
                <img src=".\docs\pictures\02\02-15.png" alt="" width=500 border="1" hspace="10"><br>
                <li>백프로파게이션, 체인 룰이라고도 불림<br></li>
                <li>가중치 조정 이후 다시 한번 결괏값 점검 → 오차가 있을 경우 오차 역전파법을 통해 가중치 수정' 과정 반복<br></li>
            </ul>
          </ul>
        </div>

      </section>
    </div>
    <script src="./docs/JavaScript/tab.js"></script> <!--Java Script 추가-->
  </body>
</html>
